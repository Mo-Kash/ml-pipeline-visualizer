Visual Machine Learning Pipeline Planner & Code Snippet Generator

Primary Objective: Build a visual, node-based planning tool that helps users design, reason about, and document ML pipelines through drag-and-drop interactions.

Core Outcomes
    1. Visual Pipeline Design
        Users design ML pipelines using drag-and-drop nodes
        Pipeline is represented as a directed graph
        Each node represents a logical ML step, not execution

    2. Structured Pipeline Validation (Lenient)
        The system validates the pipeline against a canonical ML lifecycle, while allowing flexibility for advanced users.
        Canonical Stages
        1. Data Processing
        2. Model Development
        3. Model Deployment


Validation behavior:
    Errors → structural impossibility (e.g., model before data)
    Warnings → bad practice or incompatibility
    Always allow user to proceed
    Decision Compatibility & Suggestions

    The system evaluates how well decisions fit together, such as:
        Data type vs model choice
        Feature scaling vs algorithm
        Training method vs data size
    This is rule-based, not ML-based.
    Example: Logistic Regression assumes linear separability. Consider feature engineering or a tree-based model.

Code Snippet Generation (Per Node & Per Stage)
    Each node provides copyable, editable code snippets
    Snippets are:
        Pre-written
        Framework-specific (initially: scikit-learn)
        Independent (not executed)

Later:
    Export a combined notebook (optional stretch goal)
    Diagram Export
        Export pipeline as: PNG / SVG image
        Useful for:
            Reports
            Documentation
            Presentations

Non-Goals (Explicitly Out of Scope)
    Training models
    Running experiments
    Cloud deployment
    Auto hyperparameter optimization
    Dataset hosting

High-Level System Architecture
    Frontend (Primary)
        Node editor
        Validation engine
        UI-driven suggestions
        Code snippet viewer
        Export pipeline diagram
    Backend (Optional / Lightweight)
        Rule evaluation
        Code template management
        Notebook generation (later)

Validation Philosophy (Imp)
    System uses three levels of feedback:
        | Level      | Meaning              | Behavior                           |
        | ---------- | -------------------- | ---------------------------------- |
        | Info       | Good practice        | Tooltip / suggestion               |
        | Warning    | Suboptimal / risky   | Popup / highlight                  |
        | Error      | Structurally invalid | Strong warning, but allow override |



Node System Design

DATA NODES
    Ingest Node
        Purpose: Defines data source
        Properties
            | Field        | Type    | Examples             |
            | ------------ | ------- | -------------------- |
            | Source Type  | Enum    | CSV, JSON, SQL, API  |
            | Schema Known | Boolean | Yes / No             |
            | Data Type    | Enum    | Tabular, Text, Image |
        Validation Rules
            Must be the first node
            Only one ingest node allowed
        Code Snippet Example
            import pandas as pd
            df = pd.read_csv("data.csv")

    Preprocessing Node
        Purpose: Clean & normalize data
        Options
            Missing value handling
            Scaling
            Encoding
        Properties
            | Field    | Type                          |
            | -------- | ----------------------------- |
            | Scaling  | Enum (None, Standard, MinMax) |
            | Encoding | Enum (Label, OneHot)          |
        Warnings
            Tree models don’t require scaling
            One-hot encoding + high cardinality → warning

    Exploration (EDA) Node
        Purpose: Data understanding (optional)
        Properties
            | Field    | Type                                    |
            | -------- | --------------------------------------- |
            | EDA Type | Enum (Univariate, Bivariate, Profiling) |
        Notes
            Optional node
            No effect on downstream validity
        Code Snippet example: df.describe()

    Feature Engineering Node
        Purpose: Feature transformation
        Examples
            Polynomial features
            Feature selection
            Domain transformations
        Warnings
            Polynomial features + small dataset → overfitting risk
    
    Data Splitting Node
        Purpose: Train/test/validation split
        Properties
            | Field        | Type  |
            | ------------ | ----- |
            | Train Size   | Float |
            | Test Size    | Float |
            | Random State | Int   |
        Validation
            Must appear before training
            Only one split node allowed

MODEL NODES
    Model Selection Node
        Purpose: Choose algorithm
        Supported Models (Initial)
            Linear Regression
            Logistic Regression
            Decision Tree
            Random Forest
            Properties
                | Field      | Type                          |
                | ---------- | ----------------------------- |
                | Model Name | String                        |
                | Model Type | Enum (Linear, Tree, Ensemble) |
        Compatibility Warnings
                | Model               | Warning Example     |
                | ------------------- | ------------------- |
                | Logistic Regression | Non-numeric data    |
                | Linear Regression   | Non-linear patterns |

    Training Node
        Purpose: Define training strategy
        Properties
            | Field           | Type                            |
            | --------------- | ------------------------------- |
            | Learning Type   | Enum (Supervised, Unsupervised) |
            | Hyperparameters | Key-Value                       |
        Notes
            Training is conceptual
            Hyperparameters are editable but not executed

    Evaluation Node
        Purpose: Model assessment
            Metrics
            Accuracy
            Precision / Recall
            RMSE
            Validation
            Must come after training
            Multiple evaluation nodes allowed

DEPLOYMENT NODES
    Purpose: Deployment planning (conceptual)
    Options
        Model serialization
        REST API
        Batch inference
    Properties
        | Field           | Type    |
        | --------------- | ------- |
        | Deployment Type | Enum    |
        | Monitoring      | Boolean |
    Links
        FastAPI docs
        Docker docs
        AWS/GCP references

Compatibility Engine
    Rule-based, declarative:
        IF model == "Logistic Regression"
        AND data_type != "Numeric"
        THEN warning("Logistic regression requires numeric features")


Sidebar & UX Rules
    Categorized by stage
    Drag-and-drop enabled
    User-created nodes allowed (metadata only)
    | Stage      | Color  | Shape     |
    | ---------- | ------ | --------- |
    | Data       | Blue   | Rectangle |
    | Model      | Green  | Hexagon   |
    | Deployment | Yellow | Rounded   |
